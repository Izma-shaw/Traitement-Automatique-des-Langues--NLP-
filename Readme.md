# Traitement Automatique des Langues (NLP)

## Description

Ce projet vise à explorer les techniques avancées de Traitement Automatique des Langues (TAL) afin de construire une solution complète pour l'analyse de textes en langue naturelle. L'objectif est de développer des compétences pratiques dans l'utilisation des bibliothèques Python les plus performantes pour résoudre des problèmes réels liés au NLP, tels que l'analyse des sentiments, la classification de textes, et l'extraction de caractéristiques linguistiques. Nous utilisons une combinaison puissante de bibliothèques telles que **NLTK** pour la tokenisation et la gestion des stop words, **spaCy** pour la lemmatisation rapide et l'analyse syntaxique, **Scikit-learn** pour les modèles d'apprentissage automatique, **Pandas** pour la manipulation des données, et **NumPy** pour les calculs numériques efficaces. Cette synergie permet de créer une solution robuste et polyvalente qui répond aux exigences modernes du traitement de texte automatisé.

## Fonctionnalités

- **Prétraitement des Textes** : Nettoyage, tokenisation, lemmatisation, et suppression des stop words pour préparer les données textuelles pour les modèles d'apprentissage automatique.
- **Analyse de Sentiments** : Développer une solution d'analyse des sentiments pour déterminer les émotions présentes dans les textes (positif, négatif, neutre).
- **Extraction de Caractéristiques** : Transformation des textes en vecteurs numériques (TF-IDF, BoW) pour permettre l'entraînement de modèles de machine learning.
- **Classification de Textes** : Utilisation de techniques de classification supervisée telles que la régression logistique et SVM pour catégoriser des documents en fonction de leurs contenus.

## Prérequis

- Python 3.x
- Jupyter Notebook
- Bibliothèques Python : NLTK, spaCy, Scikit-learn, Pandas, NumPy

## Installation et Lancement

1. Clonez ce dépôt sur votre machine locale :
   ```sh
   git clone <URL-du-dépôt>
   ```
2. Accédez au dossier du projet :
   ```sh
   cd chemin/vers/le/projet
   ```
3. Installez les dépendances requises :
   ```sh
   pip install -r requirements.txt
   ```
4. Lancez Jupyter Notebook :
   ```sh
   jupyter notebook
   ```
5. Ouvrez les fichiers `TP2.ipynb` et `TP_3.ipynb` pour explorer les différentes techniques de NLP abordées.

## Structure du Projet

- **Projet_1.ipynb** : Présentation des techniques de prétraitement de texte, incluant le nettoyage, la tokenisation, et la lemmatisation.
- **Projet\_2.ipynb** : Implémentation de modèles de classification et analyse des sentiments sur des jeux de données textuels.
- **requirements.txt** : Liste des bibliothèques nécessaires pour exécuter les notebooks.

## Collaborateurs

- Arafat Feical Idriss
- Ismael Sow

## Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de détails.